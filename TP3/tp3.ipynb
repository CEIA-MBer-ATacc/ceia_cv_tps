{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "832637b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edbfc0",
   "metadata": {},
   "source": [
    "### **Generalización para múltiples detecciones de un mismo template**\n",
    "\n",
    "Abarca items 1, 2 y 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "856d40ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se leyeron 7 imágenes\n"
     ]
    }
   ],
   "source": [
    "# --- Ruta de la carpeta con las imágenes ---\n",
    "directorio = \"./images\"\n",
    "\n",
    "# --- Lista para guardar las imágenes ---\n",
    "imagenes = []\n",
    "\n",
    "# --- Recorremos los archivos del directorio ---\n",
    "for archivo in os.listdir(directorio):\n",
    "    ruta_completa = os.path.join(directorio, archivo)\n",
    "\n",
    "    # --- Verificamos que sea un archivo y termine en una extensión de imagen ---\n",
    "    if os.path.isfile(ruta_completa) and archivo.lower().endswith(('.png', '.jpg')):\n",
    "        img = cv.imread(ruta_completa)\n",
    "        if img is not None:\n",
    "            imagenes.append((archivo.split(\".\")[0], img))\n",
    "        else:\n",
    "            print(f\"No se pudo leer la imagen: {archivo}\")\n",
    "\n",
    "print(f\"Se leyeron {len(imagenes)} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "980502eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_img(img):\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img_blur = cv.GaussianBlur(img_gray, (5,5), 0)\n",
    "    img_edges = cv.Canny(img_blur, 50, 150)\n",
    "    return img_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c48bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escala: 0.30 | MaxVal: 0.0665 | Detecciones: 1\n",
      "Imagen COCA-COLA-LOGO guardada con detecciones en ./resultados/COCA-COLA-LOGO_result.png\n",
      "Escala: 4.07 | MaxVal: 0.1137 | Detecciones: 14\n",
      "Imagen coca_multi guardada con detecciones en ./resultados/coca_multi_result.png\n",
      "Escala: 2.35 | MaxVal: 0.2232 | Detecciones: 1\n",
      "Imagen coca_logo_1 guardada con detecciones en ./resultados/coca_logo_1_result.png\n",
      "Escala: 0.73 | MaxVal: 0.0880 | Detecciones: 1\n",
      "Imagen coca_retro_1 guardada con detecciones en ./resultados/coca_retro_1_result.png\n",
      "Escala: 1.27 | MaxVal: 0.0990 | Detecciones: 1\n",
      "Imagen logo_1 guardada con detecciones en ./resultados/logo_1_result.png\n",
      "Escala: 1.81 | MaxVal: 0.0690 | Detecciones: 1\n",
      "Imagen coca_logo_2 guardada con detecciones en ./resultados/coca_logo_2_result.png\n",
      "Escala: 2.45 | MaxVal: 0.1629 | Detecciones: 1\n",
      "Imagen coca_retro_2 guardada con detecciones en ./resultados/coca_retro_2_result.png\n"
     ]
    }
   ],
   "source": [
    "# --- Carpeta de salida ---\n",
    "output_folder = \"./resultados\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# --- Cargar template ---\n",
    "template = cv.imread(\"./template/pattern.png\")\n",
    "template_preproc = preproc_img(template)\n",
    "h, w = template_preproc.shape\n",
    "\n",
    "# --- Factores de escala a probar ---\n",
    "scales = np.round(np.linspace(0.3, 4.5, 40), 2)  # 50% a 150%\n",
    "\n",
    "for nombre, img in imagenes:\n",
    "    best_val = -1\n",
    "    best_scale = 1.0\n",
    "    best_result = None\n",
    "    best_resized = None\n",
    "    max_roi = None\n",
    "\n",
    "    # Buscar mejor escala\n",
    "    for scale in scales:\n",
    "        i = img.copy()\n",
    "        resized = cv.resize(i, None, fx=scale, fy=scale)\n",
    "\n",
    "        if resized.shape[0] < h or resized.shape[1] < w:\n",
    "            continue\n",
    "\n",
    "        img_preproc = preproc_img(resized)\n",
    "\n",
    "        if img_preproc is None:\n",
    "            continue\n",
    "\n",
    "        result = cv.matchTemplate(img_preproc, template_preproc, cv.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "\n",
    "        # ROI de la coincidencia\n",
    "        top_left = max_loc\n",
    "        roi = img_preproc[top_left[1]:top_left[1]+h, top_left[0]:top_left[0]+w]\n",
    "\n",
    "        # Aplicamos una doble validación para eliminar flasos positivos usando ORB\n",
    "        # Nos quedamos con 100 features del template y de la ROI y consideramos\n",
    "        # true positives si hay un mínimo de 25 features coincidentes\n",
    "        orb = cv.ORB_create(nfeatures=100)\n",
    "        kp1, des1 = orb.detectAndCompute(template_preproc, None)\n",
    "        kp2, des2 = orb.detectAndCompute(roi, None)\n",
    "\n",
    "        # Evaluar si se encontraron descriptores en el template y en la ROI\n",
    "        if des1 is None or des2 is None:\n",
    "            continue\n",
    "\n",
    "        bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(des1, des2)\n",
    "\n",
    "        if len(matches) < 25:  # umbral mínimo de coincidencias\n",
    "            continue\n",
    "\n",
    "        if max_val > best_val:\n",
    "            best_val = max_val\n",
    "            best_scale = scale\n",
    "            best_result = result\n",
    "            best_resized = resized.copy()\n",
    "            max_roi = roi.copy()\n",
    "\n",
    "    # Obtener TODAS las detecciones de la mejor escala\n",
    "    if best_result is not None:\n",
    "        threshold = best_val * 0.7\n",
    "        loc = np.where(best_result >= threshold)\n",
    "        rects = []\n",
    "\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            rects.append([pt[0], pt[1], w, h])\n",
    "\n",
    "        # Agrupar rectángulos solapados\n",
    "        rects, weights = cv.groupRectangles(rects, groupThreshold=1, eps=0.5)\n",
    "\n",
    "        # Dibujar rectángulos\n",
    "        for (x, y, w, h) in rects:\n",
    "            cv.rectangle(best_resized, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Agregar métricas sobre la imagen\n",
    "        text = f\"Escala: {best_scale:.2f} | MaxVal: {best_val:.4f} | Detecciones: {len(rects)}\"\n",
    "        print(text)\n",
    "\n",
    "        # Guardar imagen\n",
    "        output_path = os.path.join(output_folder, f\"{nombre}_result.png\")\n",
    "        cv.imwrite(output_path, best_resized)\n",
    "\n",
    "        if max_roi is not None:\n",
    "            output_path = os.path.join(output_folder, f\"{nombre}_roi.png\")\n",
    "            cv.imwrite(output_path, max_roi)\n",
    "\n",
    "        print(f\"Imagen {nombre} guardada con detecciones en {os.path.join(output_folder, f'{nombre}_result.png')}\")\n",
    "    else:\n",
    "        print(\"No se encontró coincidencia.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80ce9d4",
   "metadata": {},
   "source": [
    "### **Conclusiones**\n",
    "\n",
    "Se realizó un resize de las imágenes objetivos entre las escalas 0.3 y 4.5 con 40 pasos entre ellas.\n",
    "\n",
    "Se hizo un preprocesamiento tanto del template como las imágenes usando primero conversión a escala de grises, desenfoque Gaussiano y detección de bordes mediante método de Canny.\n",
    "\n",
    "Se aplicó matching template sobre las escalas, quedándose con la ROI de cada imagen (preprocesada) con mejor correlación. Luego se aplicó una doble validación para eliminar flasos positivos usando ORB entre la ROI y el template. Nos quedamos con 100 features del template y de la ROI, y consideramos true positives si hay un mínimo de 25 features coincidentes.\n",
    "\n",
    "Además, para poder hacer múltiples detecciones se tomo el valor de correlación de la ROI y se utilizó como umbral un 70% de este para mostrar el resto de detecciones.\n",
    "\n",
    "Finalmente se unificó el código para agrupar todos recuadros de los matches de manera de no tener superposiciones y se mostró la mejor correlación obtenida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
